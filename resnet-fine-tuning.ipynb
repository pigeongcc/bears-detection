{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"!pip install roboflow\n!pip install torchmetrics","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xnl8KpFGjj_a","outputId":"e6f23443-655e-47de-f893-25f5aacf8749"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\nfrom __future__ import division\n\nfrom os.path import join\nfrom roboflow import Roboflow\nfrom torchvision import datasets, models, transforms\nfrom torchmetrics.classification import BinaryAccuracy, BinaryPrecision, BinaryRecall, BinaryF1Score\nfrom torchvision.io import read_image, ImageReadMode\nfrom torchvision.models import resnet152, ResNet152_Weights\nfrom torch.utils.data import Dataset\nfrom tqdm import tqdm\n\nimport copy\nimport matplotlib.pyplot as plt\nimport os\nimport pandas as pd\nimport time\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport numpy as np","metadata":{"id":"9Uxrm-uojj_b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fine-Tuning","metadata":{"id":"6iHd1PnKjj_c"}},{"cell_type":"code","source":"def train_model(model, dataloaders, criterion, optimizer, scheduler=None, num_epochs=25):\n    since = time.time()\n    \n    metrics = {\n        'accuracy': BinaryAccuracy(),\n        'precision': BinaryPrecision(),\n        'recall': BinaryRecall(),\n        'f1': BinaryF1Score(),\n    }\n    metrics_history = {}\n    for metric in metrics.keys():\n        metrics_history[metric] = []\n\n    best_model_weights = copy.deepcopy(model.state_dict())\n    best_f1 = 0.0\n\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs - 1}')\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            preds_epoch = []\n            targets_epoch = []\n            \n            # Iterate over data\n            for X_batch, y_batch in tqdm(dataloaders[phase]):\n                X_batch = X_batch.to(device)\n                y_batch = y_batch.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    # Get model outputs and calculate loss\n                    outputs = model(X_batch)\n                    loss = criterion(outputs, y_batch)\n\n                    _, preds = torch.max(outputs, 1)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                preds_epoch.extend(preds.tolist())\n                targets_epoch.extend(y_batch.tolist())\n                running_loss += loss.item() * X_batch.size(0)\n                running_corrects += torch.sum(preds == y_batch.data)\n\n            preds_epoch = torch.Tensor(preds_epoch)\n            targets_epoch = torch.Tensor(targets_epoch)\n            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n            epoch_acc_original = running_corrects.double() / len(dataloaders[phase].dataset)\n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc_original:.4f}')\n\n            for metric_name, metric_obj in metrics.items():\n                metric_val = metric_obj(preds_epoch, targets_epoch)\n                print(f'{phase} {metric_name}: {metric_val:.4f}')\n                if phase == 'val':\n                    # save metrics values\n                    metrics_history[metric_name].append(metric_val)\n                    \n            if phase == 'val':\n                # deep copy if the model is best\n                epoch_f1 = metrics_history['f1'][-1]\n                if epoch_f1 > best_f1:\n                    best_f1 = epoch_f1\n                    best_model_weights = copy.deepcopy(model.state_dict())\n        \n        if scheduler is not None:\n            scheduler.step()\n        print()\n\n    time_elapsed = time.time() - since\n    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'Best val F1: {best_f1:4f}')\n\n    # load best model weights\n    model.load_state_dict(best_model_weights)\n    return model, metrics_history","metadata":{"execution":{"iopub.status.busy":"2023-03-23T12:27:50.765112Z","iopub.execute_input":"2023-03-23T12:27:50.765516Z","iopub.status.idle":"2023-03-23T12:27:50.784737Z","shell.execute_reply.started":"2023-03-23T12:27:50.765477Z","shell.execute_reply":"2023-03-23T12:27:50.783662Z"},"id":"XW1-jkYMjj_d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"When feature extracting, we do not need to compute the gradients\nof all the NN parameters except of the last layer ones.\nSo for efficiency we set the `requires_grad` attribute to False.\n\nBy default, this attribute is set to True.\n\nWhen finetuning, we leave all (or some) of the `required_grad`\nparameters set to True.\n\"\"\"\ndef set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        for param in model.parameters():\n            param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2023-03-23T12:27:50.786674Z","iopub.execute_input":"2023-03-23T12:27:50.787426Z","iopub.status.idle":"2023-03-23T12:27:50.800457Z","shell.execute_reply.started":"2023-03-23T12:27:50.787388Z","shell.execute_reply":"2023-03-23T12:27:50.799369Z"},"id":"bMpDNs4xjj_e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"PyTorch Version: \", torch.__version__)\nprint(\"Torchvision Version: \", torchvision.__version__)\nprint()\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"device:\", device)\n\nINPUT_SIZE = 224\nNUM_CLASSES = 2\nBATCH_SIZE = 32\nNUM_EPOCHS = 30\nfeature_extract = True\n\n# Loading a pre-trained image classification model\nweights = ResNet152_Weights.DEFAULT\nresnet = resnet152(weights=weights)\n# setting `requires_grad` parameters (finetuning - True, feature extraction - False)\nset_parameter_requires_grad(resnet, feature_extract)\n# changing the number of neurons of the output layer\nresnet.fc = nn.Linear(resnet.fc.in_features, NUM_CLASSES)\nprint(\"Output layer:\", resnet.fc)\n# Getting the preprocessing necessary for the model\npreprocess = weights.transforms()","metadata":{"execution":{"iopub.status.busy":"2023-03-23T12:27:50.801792Z","iopub.execute_input":"2023-03-23T12:27:50.802784Z","iopub.status.idle":"2023-03-23T12:27:52.036592Z","shell.execute_reply.started":"2023-03-23T12:27:50.802748Z","shell.execute_reply":"2023-03-23T12:27:52.035295Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"4sP-I5ihjj_e","outputId":"e6e40024-6c04-45b6-9dca-f4b67d6a4597","trusted":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"PyTorch Version:  1.13.1+cu116\n\nTorchvision Version:  0.14.1+cu116\n\n\n\nOutput layer: Linear(in_features=2048, out_features=2, bias=True)\n"}]},{"cell_type":"markdown","source":"## Data Loaders and Transforms","metadata":{"id":"7NKwydvYjj_f"}},{"cell_type":"code","source":"rf = Roboflow(api_key=\"ZsZB2FnCmcNaslwIlejv\")\nproject = rf.workspace(\"mydatasets-bqwxe\").project(\"kaggle-kontur\")\ndataset = project.version(8).download(\"multiclass\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NmMY-a7Kjj_f","outputId":"31884e94-ef1e-4153-b1ac-eb02decc75e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"loading Roboflow workspace...\n\nloading Roboflow project...\n\nDownloading Dataset Version Zip in Kaggle-Kontur-8 to multiclass: 96% [93831168 / 97352603] bytes"},{"output_type":"stream","name":"stderr","text":"Extracting Dataset Version Zip to Kaggle-Kontur-8 in multiclass:: 100%|██████████| 944/944 [00:00<00:00, 985.21it/s] \n"}]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, img_dir, df, transform=None, target_transform=None):\n        self.img_dir = img_dir\n        self.df = df\n        self.transform = transform\n        self.target_transform = target_transform\n        \n        # save image paths\n        img_names = df['filename']\n        img_paths = [os.path.join(img_dir, img_name) for img_name in img_names]\n        self.df['img_path'] = img_paths\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        image = read_image(self.df.iloc[idx]['img_path'], mode=ImageReadMode.RGB)\n        label = self.df.iloc[idx][' 1-0']\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n            \n        return image, label","metadata":{"execution":{"iopub.status.busy":"2023-03-23T12:27:52.039542Z","iopub.execute_input":"2023-03-23T12:27:52.040197Z","iopub.status.idle":"2023-03-23T12:27:52.051941Z","shell.execute_reply.started":"2023-03-23T12:27:52.040156Z","shell.execute_reply":"2023-03-23T12:27:52.050666Z"},"id":"0G2pE58Ijj_f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"/content/Kaggle-Kontur-8/train/_classes.csv\")\ndf_valid = pd.read_csv(\"/content/Kaggle-Kontur-8/valid/_classes.csv\")\n\ntrain_loader = CustomDataset('/content/Kaggle-Kontur-8/train', df_train, preprocess)\nvalid_loader = CustomDataset('/content/Kaggle-Kontur-8/valid', df_valid, preprocess)\n\ndataloaders_dict = {\n    'train': torch.utils.data.DataLoader(train_loader, batch_size=BATCH_SIZE, shuffle=True, num_workers=2),\n    'val': torch.utils.data.DataLoader(valid_loader, batch_size=BATCH_SIZE, shuffle=True, num_workers=2),\n}","metadata":{"execution":{"iopub.status.busy":"2023-03-23T12:27:52.053884Z","iopub.execute_input":"2023-03-23T12:27:52.054292Z","iopub.status.idle":"2023-03-23T12:27:52.093099Z","shell.execute_reply.started":"2023-03-23T12:27:52.054251Z","shell.execute_reply":"2023-03-23T12:27:52.091969Z"},"id":"yU2pxZgdjj_f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us check the training set class balance:","metadata":{"id":"SjLUWVIJjj_g"}},{"cell_type":"code","source":"df_train[' 1-0'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-03-23T12:27:52.095174Z","iopub.execute_input":"2023-03-23T12:27:52.095673Z","iopub.status.idle":"2023-03-23T12:27:52.105561Z","shell.execute_reply.started":"2023-03-23T12:27:52.095628Z","shell.execute_reply":"2023-03-23T12:27:52.104107Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"qetkGqDXjj_g","outputId":"952cb7b1-26ae-4ab6-c664-6728433d8c8b","trusted":true},"execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":["0    633\n","1    237\n","Name:  1-0, dtype: int64"]},"metadata":{}}]},{"cell_type":"markdown","source":"The classes are slightly imbalanced. Besides accuracy, it's better to check Precision and Recall metrics also.","metadata":{"id":"BADENfSXjj_g"}},{"cell_type":"markdown","source":"## Updating the CNN Weights","metadata":{"id":"Kbs77E06jj_g"}},{"cell_type":"code","source":"def get_updatable_parameters(model, feature_extracting, verbose=True):\n    print(\"Params to learn:\")\n    if feature_extracting:\n        params_to_update = []\n        for name,param in model.named_parameters():\n            if param.requires_grad == True:\n                params_to_update.append(param)\n                if verbose:\n                    print(\"\\t\",name)\n    else:\n        params_to_update = model.parameters()\n        for name,param in model.named_parameters():\n            if param.requires_grad == True:\n                if verbose:\n                    print(\"\\t\",name)\n                \n    return params_to_update","metadata":{"execution":{"iopub.status.busy":"2023-03-23T12:27:52.120911Z","iopub.execute_input":"2023-03-23T12:27:52.121761Z","iopub.status.idle":"2023-03-23T12:27:52.131059Z","shell.execute_reply.started":"2023-03-23T12:27:52.121714Z","shell.execute_reply":"2023-03-23T12:27:52.130099Z"},"id":"UXmYebINjj_h","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Send the model to GPU\nresnet = resnet.to(device)\n\n\n\"\"\" Gather the parameters to be optimized/updated in this run. If we are\nfinetuning we will be updating all parameters. However, if we are\ndoing feature extract method, we will only update the parameters\nthat we have just initialized, i.e. the parameters with requires_grad is True.\n\"\"\"\nlayers_to_unfreeze = [resnet.fc, resnet.avgpool, resnet.layer4]\nfor layer in layers_to_unfreeze:\n    for param in layer.parameters():\n        param.requires_grad = True\n\nparams_to_update = get_updatable_parameters(resnet, feature_extract)","metadata":{"execution":{"iopub.status.busy":"2023-03-23T12:27:52.156841Z","iopub.execute_input":"2023-03-23T12:27:52.157168Z","iopub.status.idle":"2023-03-23T12:27:52.259478Z","shell.execute_reply.started":"2023-03-23T12:27:52.157140Z","shell.execute_reply":"2023-03-23T12:27:52.258454Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"0Rd1GLhXjj_h","outputId":"9a5d09a5-3a0e-4032-cc3d-139c9d94393a","trusted":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Params to learn:\n\n\t layer4.0.conv1.weight\n\n\t layer4.0.bn1.weight\n\n\t layer4.0.bn1.bias\n\n\t layer4.0.conv2.weight\n\n\t layer4.0.bn2.weight\n\n\t layer4.0.bn2.bias\n\n\t layer4.0.conv3.weight\n\n\t layer4.0.bn3.weight\n\n\t layer4.0.bn3.bias\n\n\t layer4.0.downsample.0.weight\n\n\t layer4.0.downsample.1.weight\n\n\t layer4.0.downsample.1.bias\n\n\t layer4.1.conv1.weight\n\n\t layer4.1.bn1.weight\n\n\t layer4.1.bn1.bias\n\n\t layer4.1.conv2.weight\n\n\t layer4.1.bn2.weight\n\n\t layer4.1.bn2.bias\n\n\t layer4.1.conv3.weight\n\n\t layer4.1.bn3.weight\n\n\t layer4.1.bn3.bias\n\n\t layer4.2.conv1.weight\n\n\t layer4.2.bn1.weight\n\n\t layer4.2.bn1.bias\n\n\t layer4.2.conv2.weight\n\n\t layer4.2.bn2.weight\n\n\t layer4.2.bn2.bias\n\n\t layer4.2.conv3.weight\n\n\t layer4.2.bn3.weight\n\n\t layer4.2.bn3.bias\n\n\t fc.weight\n\n\t fc.bias\n"}]},{"cell_type":"code","source":"optimizer = optim.AdamW(params_to_update)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5, verbose=True)\ncriterion = nn.CrossEntropyLoss()\n\n# Train and evaluate\nresnet_ft, metrics_history = train_model(resnet, dataloaders_dict, criterion, optimizer, scheduler, num_epochs=NUM_EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2023-03-23T12:27:52.260786Z","iopub.execute_input":"2023-03-23T12:27:52.261465Z","iopub.status.idle":"2023-03-23T12:29:28.949685Z","shell.execute_reply.started":"2023-03-23T12:27:52.261434Z","shell.execute_reply":"2023-03-23T12:29:28.948231Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"Tf7VXq_-jj_h","outputId":"7d7fcb31-a66d-4cbf-a82e-1191c0ac3135","trusted":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-03.\n\nEpoch 0/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:11<00:00,  2.53it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.1074 Acc: 0.9632\n\ntrain accuracy: 0.9632\n\ntrain precision: 0.9476\n\ntrain recall: 0.9156\n\ntrain f1: 0.9313\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.89it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.1191 Acc: 0.9706\n\nval accuracy: 0.9706\n\nval precision: 0.9545\n\nval recall: 0.9545\n\nval f1: 0.9545\n\nAdjusting learning rate of group 0 to 1.0000e-03.\n\n\n\nEpoch 1/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:08<00:00,  3.43it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0152 Acc: 0.9977\n\ntrain accuracy: 0.9977\n\ntrain precision: 0.9958\n\ntrain recall: 0.9958\n\ntrain f1: 0.9958\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.04it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.0749 Acc: 0.9853\n\nval accuracy: 0.9853\n\nval precision: 1.0000\n\nval recall: 0.9545\n\nval f1: 0.9767\n\nAdjusting learning rate of group 0 to 1.0000e-03.\n\n\n\nEpoch 2/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:09<00:00,  2.95it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0017 Acc: 1.0000\n\ntrain accuracy: 1.0000\n\ntrain precision: 1.0000\n\ntrain recall: 1.0000\n\ntrain f1: 1.0000\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.1173 Acc: 0.9706\n\nval accuracy: 0.9706\n\nval precision: 1.0000\n\nval recall: 0.9091\n\nval f1: 0.9524\n\nAdjusting learning rate of group 0 to 1.0000e-03.\n\n\n\nEpoch 3/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:13<00:00,  2.08it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0003 Acc: 1.0000\n\ntrain accuracy: 1.0000\n\ntrain precision: 1.0000\n\ntrain recall: 1.0000\n\ntrain f1: 1.0000\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.26it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.1031 Acc: 0.9853\n\nval accuracy: 0.9853\n\nval precision: 1.0000\n\nval recall: 0.9545\n\nval f1: 0.9767\n\nAdjusting learning rate of group 0 to 1.0000e-03.\n\n\n\nEpoch 4/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:08<00:00,  3.40it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0036 Acc: 0.9989\n\ntrain accuracy: 0.9989\n\ntrain precision: 0.9958\n\ntrain recall: 1.0000\n\ntrain f1: 0.9979\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.75it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.1702 Acc: 0.9853\n\nval accuracy: 0.9853\n\nval precision: 0.9565\n\nval recall: 1.0000\n\nval f1: 0.9778\n\nAdjusting learning rate of group 0 to 5.0000e-04.\n\n\n\nEpoch 5/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:09<00:00,  3.03it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0027 Acc: 1.0000\n\ntrain accuracy: 1.0000\n\ntrain precision: 1.0000\n\ntrain recall: 1.0000\n\ntrain f1: 1.0000\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.72it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.0661 Acc: 0.9706\n\nval accuracy: 0.9706\n\nval precision: 0.9545\n\nval recall: 0.9545\n\nval f1: 0.9545\n\nAdjusting learning rate of group 0 to 5.0000e-04.\n\n\n\nEpoch 6/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:09<00:00,  3.04it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0150 Acc: 0.9943\n\ntrain accuracy: 0.9943\n\ntrain precision: 0.9915\n\ntrain recall: 0.9873\n\ntrain f1: 0.9894\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.81it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.2940 Acc: 0.9559\n\nval accuracy: 0.9559\n\nval precision: 0.9524\n\nval recall: 0.9091\n\nval f1: 0.9302\n\nAdjusting learning rate of group 0 to 5.0000e-04.\n\n\n\nEpoch 7/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:08<00:00,  3.12it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0072 Acc: 1.0000\n\ntrain accuracy: 1.0000\n\ntrain precision: 1.0000\n\ntrain recall: 1.0000\n\ntrain f1: 1.0000\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.50it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.0797 Acc: 0.9706\n\nval accuracy: 0.9706\n\nval precision: 0.9545\n\nval recall: 0.9545\n\nval f1: 0.9545\n\nAdjusting learning rate of group 0 to 5.0000e-04.\n\n\n\nEpoch 8/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:07<00:00,  3.52it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0008 Acc: 1.0000\n\ntrain accuracy: 1.0000\n\ntrain precision: 1.0000\n\ntrain recall: 1.0000\n\ntrain f1: 1.0000\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.82it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.1067 Acc: 0.9706\n\nval accuracy: 0.9706\n\nval precision: 0.9545\n\nval recall: 0.9545\n\nval f1: 0.9545\n\nAdjusting learning rate of group 0 to 5.0000e-04.\n\n\n\nEpoch 9/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:09<00:00,  3.05it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0003 Acc: 1.0000\n\ntrain accuracy: 1.0000\n\ntrain precision: 1.0000\n\ntrain recall: 1.0000\n\ntrain f1: 1.0000\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.74it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.0867 Acc: 0.9706\n\nval accuracy: 0.9706\n\nval precision: 0.9545\n\nval recall: 0.9545\n\nval f1: 0.9545\n\nAdjusting learning rate of group 0 to 2.5000e-04.\n\n\n\nEpoch 10/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:09<00:00,  3.00it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0043 Acc: 0.9989\n\ntrain accuracy: 0.9989\n\ntrain precision: 1.0000\n\ntrain recall: 0.9958\n\ntrain f1: 0.9979\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.78it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.1105 Acc: 0.9559\n\nval accuracy: 0.9559\n\nval precision: 0.9524\n\nval recall: 0.9091\n\nval f1: 0.9302\n\nAdjusting learning rate of group 0 to 2.5000e-04.\n\n\n\nEpoch 11/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:09<00:00,  3.02it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0110 Acc: 0.9989\n\ntrain accuracy: 0.9989\n\ntrain precision: 0.9958\n\ntrain recall: 1.0000\n\ntrain f1: 0.9979\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.81it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.1385 Acc: 0.9706\n\nval accuracy: 0.9706\n\nval precision: 0.9545\n\nval recall: 0.9545\n\nval f1: 0.9545\n\nAdjusting learning rate of group 0 to 2.5000e-04.\n\n\n\nEpoch 12/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:08<00:00,  3.21it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0059 Acc: 0.9989\n\ntrain accuracy: 0.9989\n\ntrain precision: 1.0000\n\ntrain recall: 0.9958\n\ntrain f1: 0.9979\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.0974 Acc: 0.9706\n\nval accuracy: 0.9706\n\nval precision: 0.9545\n\nval recall: 0.9545\n\nval f1: 0.9545\n\nAdjusting learning rate of group 0 to 2.5000e-04.\n\n\n\nEpoch 13/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:09<00:00,  3.11it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0012 Acc: 1.0000\n\ntrain accuracy: 1.0000\n\ntrain precision: 1.0000\n\ntrain recall: 1.0000\n\ntrain f1: 1.0000\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.43it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.1202 Acc: 0.9853\n\nval accuracy: 0.9853\n\nval precision: 0.9565\n\nval recall: 1.0000\n\nval f1: 0.9778\n\nAdjusting learning rate of group 0 to 2.5000e-04.\n\n\n\nEpoch 14/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:09<00:00,  2.97it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0007 Acc: 1.0000\n\ntrain accuracy: 1.0000\n\ntrain precision: 1.0000\n\ntrain recall: 1.0000\n\ntrain f1: 1.0000\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.70it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.0998 Acc: 0.9706\n\nval accuracy: 0.9706\n\nval precision: 0.9545\n\nval recall: 0.9545\n\nval f1: 0.9545\n\nAdjusting learning rate of group 0 to 1.2500e-04.\n\n\n\nEpoch 15/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:09<00:00,  2.88it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0005 Acc: 1.0000\n\ntrain accuracy: 1.0000\n\ntrain precision: 1.0000\n\ntrain recall: 1.0000\n\ntrain f1: 1.0000\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.74it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.1049 Acc: 0.9706\n\nval accuracy: 0.9706\n\nval precision: 0.9545\n\nval recall: 0.9545\n\nval f1: 0.9545\n\nAdjusting learning rate of group 0 to 1.2500e-04.\n\n\n\nEpoch 16/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:09<00:00,  3.05it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0004 Acc: 1.0000\n\ntrain accuracy: 1.0000\n\ntrain precision: 1.0000\n\ntrain recall: 1.0000\n\ntrain f1: 1.0000\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.77it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.1179 Acc: 0.9706\n\nval accuracy: 0.9706\n\nval precision: 0.9545\n\nval recall: 0.9545\n\nval f1: 0.9545\n\nAdjusting learning rate of group 0 to 1.2500e-04.\n\n\n\nEpoch 17/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:08<00:00,  3.25it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0005 Acc: 1.0000\n\ntrain accuracy: 1.0000\n\ntrain precision: 1.0000\n\ntrain recall: 1.0000\n\ntrain f1: 1.0000\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.1156 Acc: 0.9706\n\nval accuracy: 0.9706\n\nval precision: 0.9545\n\nval recall: 0.9545\n\nval f1: 0.9545\n\nAdjusting learning rate of group 0 to 1.2500e-04.\n\n\n\nEpoch 18/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:08<00:00,  3.36it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0004 Acc: 1.0000\n\ntrain accuracy: 1.0000\n\ntrain precision: 1.0000\n\ntrain recall: 1.0000\n\ntrain f1: 1.0000\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.70it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.1000 Acc: 0.9706\n\nval accuracy: 0.9706\n\nval precision: 0.9545\n\nval recall: 0.9545\n\nval f1: 0.9545\n\nAdjusting learning rate of group 0 to 1.2500e-04.\n\n\n\nEpoch 19/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:09<00:00,  3.01it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0006 Acc: 1.0000\n\ntrain accuracy: 1.0000\n\ntrain precision: 1.0000\n\ntrain recall: 1.0000\n\ntrain f1: 1.0000\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.75it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.1412 Acc: 0.9853\n\nval accuracy: 0.9853\n\nval precision: 0.9565\n\nval recall: 1.0000\n\nval f1: 0.9778\n\nAdjusting learning rate of group 0 to 6.2500e-05.\n\n\n\nEpoch 20/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:09<00:00,  2.91it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0002 Acc: 1.0000\n\ntrain accuracy: 1.0000\n\ntrain precision: 1.0000\n\ntrain recall: 1.0000\n\ntrain f1: 1.0000\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.76it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.1152 Acc: 0.9706\n\nval accuracy: 0.9706\n\nval precision: 0.9545\n\nval recall: 0.9545\n\nval f1: 0.9545\n\nAdjusting learning rate of group 0 to 6.2500e-05.\n\n\n\nEpoch 21/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:09<00:00,  3.04it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0003 Acc: 1.0000\n\ntrain accuracy: 1.0000\n\ntrain precision: 1.0000\n\ntrain recall: 1.0000\n\ntrain f1: 1.0000\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.70it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.1049 Acc: 0.9706\n\nval accuracy: 0.9706\n\nval precision: 0.9545\n\nval recall: 0.9545\n\nval f1: 0.9545\n\nAdjusting learning rate of group 0 to 6.2500e-05.\n\n\n\nEpoch 22/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:08<00:00,  3.39it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0003 Acc: 1.0000\n\ntrain accuracy: 1.0000\n\ntrain precision: 1.0000\n\ntrain recall: 1.0000\n\ntrain f1: 1.0000\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.36it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.1097 Acc: 0.9706\n\nval accuracy: 0.9706\n\nval precision: 0.9545\n\nval recall: 0.9545\n\nval f1: 0.9545\n\nAdjusting learning rate of group 0 to 6.2500e-05.\n\n\n\nEpoch 23/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:09<00:00,  3.08it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0003 Acc: 1.0000\n\ntrain accuracy: 1.0000\n\ntrain precision: 1.0000\n\ntrain recall: 1.0000\n\ntrain f1: 1.0000\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.72it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.1114 Acc: 0.9706\n\nval accuracy: 0.9706\n\nval precision: 0.9545\n\nval recall: 0.9545\n\nval f1: 0.9545\n\nAdjusting learning rate of group 0 to 6.2500e-05.\n\n\n\nEpoch 24/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:09<00:00,  2.94it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0002 Acc: 1.0000\n\ntrain accuracy: 1.0000\n\ntrain precision: 1.0000\n\ntrain recall: 1.0000\n\ntrain f1: 1.0000\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.73it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.1115 Acc: 0.9853\n\nval accuracy: 0.9853\n\nval precision: 0.9565\n\nval recall: 1.0000\n\nval f1: 0.9778\n\nAdjusting learning rate of group 0 to 3.1250e-05.\n\n\n\nEpoch 25/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:09<00:00,  3.02it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0002 Acc: 1.0000\n\ntrain accuracy: 1.0000\n\ntrain precision: 1.0000\n\ntrain recall: 1.0000\n\ntrain f1: 1.0000\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.78it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.0936 Acc: 0.9706\n\nval accuracy: 0.9706\n\nval precision: 0.9545\n\nval recall: 0.9545\n\nval f1: 0.9545\n\nAdjusting learning rate of group 0 to 3.1250e-05.\n\n\n\nEpoch 26/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:08<00:00,  3.24it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0040 Acc: 0.9989\n\ntrain accuracy: 0.9989\n\ntrain precision: 0.9958\n\ntrain recall: 1.0000\n\ntrain f1: 0.9979\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.02it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.1066 Acc: 0.9706\n\nval accuracy: 0.9706\n\nval precision: 0.9545\n\nval recall: 0.9545\n\nval f1: 0.9545\n\nAdjusting learning rate of group 0 to 3.1250e-05.\n\n\n\nEpoch 27/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:08<00:00,  3.38it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0002 Acc: 1.0000\n\ntrain accuracy: 1.0000\n\ntrain precision: 1.0000\n\ntrain recall: 1.0000\n\ntrain f1: 1.0000\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.63it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.0866 Acc: 0.9706\n\nval accuracy: 0.9706\n\nval precision: 0.9545\n\nval recall: 0.9545\n\nval f1: 0.9545\n\nAdjusting learning rate of group 0 to 3.1250e-05.\n\n\n\nEpoch 28/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:09<00:00,  2.92it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0002 Acc: 1.0000\n\ntrain accuracy: 1.0000\n\ntrain precision: 1.0000\n\ntrain recall: 1.0000\n\ntrain f1: 1.0000\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.80it/s]\n"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.0814 Acc: 0.9706\n\nval accuracy: 0.9706\n\nval precision: 0.9545\n\nval recall: 0.9545\n\nval f1: 0.9545\n\nAdjusting learning rate of group 0 to 3.1250e-05.\n\n\n\nEpoch 29/29\n\n----------\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 28/28 [00:09<00:00,  3.00it/s]\n"},{"output_type":"stream","name":"stdout","text":"train Loss: 0.0002 Acc: 1.0000\n\ntrain accuracy: 1.0000\n\ntrain precision: 1.0000\n\ntrain recall: 1.0000\n\ntrain f1: 1.0000\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 3/3 [00:01<00:00,  2.75it/s]"},{"output_type":"stream","name":"stdout","text":"val Loss: 0.0807 Acc: 0.9706\n\nval accuracy: 0.9706\n\nval precision: 0.9545\n\nval recall: 0.9545\n\nval f1: 0.9545\n\nAdjusting learning rate of group 0 to 1.5625e-05.\n\n\n\nTraining complete in 5m 15s\n\nBest val F1: 0.977778\n"},{"output_type":"stream","name":"stderr","text":"\n"}]},{"cell_type":"markdown","source":"# Inference\n\nLet us detect brown bears and collect the predicted bears in the dataframe","metadata":{"id":"AyNuR050wKY-"}},{"cell_type":"code","source":"def classify(model, df, transform, device):\n    model.eval()\n    file_names = []\n    img_paths = []\n    preds = []\n    for idx, row in df.iterrows():\n        # read and transform the image\n        img = read_image(row['img_path'], mode=ImageReadMode.RGB)\n        img = transform(img)\n        img = img.unsqueeze(0).to(device)\n        # predict\n        with torch.no_grad():\n            output = model(img)\n            pred = output.data.cpu().numpy().argmax()\n        # save outputs\n        file_names.append(row['filename'])\n        img_paths.append(row['img_path'])\n        preds.append(pred)\n        \n    content = {\n        'file_name': file_names,\n        'img_path': img_paths,\n        'pred': preds,\n    }\n    return pd.DataFrame(content)","metadata":{"id":"DdP6n5z-wJAs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_preds = classify(resnet_ft, valid_loader.df, preprocess, device)","metadata":{"id":"Siv2cyh9xV44"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_preds['pred'].value_counts()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AH7SodDfjj_h","outputId":"47761228-873c-4b01-816f-54f2d78d6758"},"execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":["0    45\n","1    23\n","Name: pred, dtype: int64"]},"metadata":{}}]},{"cell_type":"markdown","source":"# Saving the model and results","metadata":{}},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NCkXwsOg5D42","outputId":"054f9e2f-eff1-485f-e203-f8f2fb13ed80"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Mounted at /content/drive\n"}]},{"cell_type":"code","source":"model_filename = f'resnet_ft_{NUM_EPOCHS}ep.pt'\nmodel_path = f'/content/{model_filename}'\n\ntorch.save(resnet_ft, model_path)\n!cp -i {model_path} /content/drive/MyDrive/kaggle_kontur/{model_filename}","metadata":{"execution":{"iopub.status.busy":"2023-03-23T12:33:53.997436Z","iopub.execute_input":"2023-03-23T12:33:53.998143Z","iopub.status.idle":"2023-03-23T12:33:54.602653Z","shell.execute_reply.started":"2023-03-23T12:33:53.998105Z","shell.execute_reply":"2023-03-23T12:33:54.601619Z"},"id":"28TBkmhGjj_h","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_preds.to_csv('/content/df_preds.csv')","metadata":{"id":"QZdpID32y7Nm"},"execution_count":null,"outputs":[]}]}